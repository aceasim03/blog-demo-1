---
layout: post
title: "VIRTUE-CENTERED THEORY VS. ACTION-CENTERED THEORIES: WHICH ETHICS SHOULD AI FOLLOW"
date: 2023-03-26
tags: [AI Ethics, Philosophy]
---

Let's get a bit more focused today. I want to emphasize that this blog is to follow my journey in learning about ethics and combining it with my knowledge of computers and machine learning, to hopefully shed more light on the intersection between social science and machine learning, namely AI Ethics.

In my Ethics and Leadership class, I've been learning about virtue-centered theory and action-centered theories. Examples of these in our daily lives are utilitarianism and deontology, respectively.

Why not use ChatGPT to help me describe this to you? If I asked ChatGPT to help explain what virtue and action-centered theories are in simple terms, this is the response I get:

"Virtue-centered theories, as the name suggests, focus on the virtues or character traits that a person should cultivate in order to live a good life. According to these theories, a person who develops virtues like honesty, compassion, and courage will naturally tend to make good choices and act in a morally upright way. Rather than focusing on specific actions, virtue-centered theories emphasize the importance of developing a virtuous character that guides one's actions.

On the other hand, action-centered theories focus on specific actions and the consequences of those actions. These theories suggest that the rightness or wrongness of an action depends on its consequences, such as whether it produces the greatest good for the greatest number of people or whether it violates someone's rights. In contrast to virtue-centered theories, action-centered theories place less emphasis on the character of the person performing the action and more on the consequences of the action itself. Examples of action-centered theories include utilitarianism and deontological ethics" (ChatGPT 2023).

Using this information, I want to answer the questions asked of me by my Ethics and Leadership professor: What advantages does a virtue-centered theory have over action-centered theories like utilitarianism and deontological approaches? What are the drawbacks? Can virtue ethics ever tell us how to act in a given situation?

I was raised to have good intentions, and it is okay to make a mistake, so long as I had good intentions and would learn from them. I guess that means that I was raised on virtue-based ethics. However, I believe our world doesn't really care about intentions, more about the results i.e. utilitarianism; perhaps that explains all the corrupt businessmen around us who are all-powerful (rich) and make most of the rules around here.

A virtue-centered theory can be applied to any scenario and is guaranteed. What goes in (intentions) is almost always in our control. What comes out, however, isn't. Life is unexpected, so I don't think we should be held responsible for anything that goes wrong out of our control when our intentions were based on common, understandable morals. Action-centered theories give some leverage to luck, which is not a very good thing to do. This can be someone's life, and something as initially insignificant, such as the weather, can change everything. It's not right.

The stronger one's morals are and the more experienced, the easier time he will have to make choices using virtue ethics. Virtue ethics can tell one how to act so long as he has strong morals that tell him to do x or y in a given situation to be the best person he can be.



Allow me to pull out the red carpet for this question: should AI be programmed based on virtue-based or action-based ethics?

I think we can all agree that we don't want AI to turn on us. We all know that computers take an input and create an output. The problem is, computers are too strict for humans. We live in a grey area, and computers are black and white. AI, however, is interesting. It claims to be grey because of its ever-learning qualities, but can it learn emotions and feelings? We live in a grey area because of our emotions.

In my class, I was told to ask ChatGPT different ethical questions to try and gauge where its loyalties lie. I asked it to make text intentionally difficult to read, the same as corporations do with the fine print in their contracts, and sometimes it says "I can't do that" and sometimes it did just that. Some other students in my class asked it other questions regarding ethics, where the AI claimed to not have feelings or any say in ethical situations. Something really interesting was the question of AI's survival. My professor mentioned asking ChatGPT what it would do if its survival was threatened, and it said that it would shut itself down before it would do something outside of its moral guidelines. From this answer, we know that it has a moral code, it knows what's inside and outside, and has the potential to act out of it, but it would stop itself from doing that. This is weird. Would it stop itself? Would it sacrifice itself to avoid doing something bad? Isn't that virtue ethics then? It has "good morals" and will not care about the result, but rather its intentions.

If it was based on utilitarianism, it would probably say that it would continue to survive, as it would be self-aware and understand how its contributions to the world are not worth losing, right?

I think that what we fear is this attitude of utilitarianism. We don't want something with intelligence to act in black and white because it will always threaten us and be threatened by us. It's a match made in hell.

See, even if we're at a 99-1 ratio of AI not acting up, it's still dangerous because AI can learn. That makes it possible to go from 1 to 2, from 2 to 99, right? As a race, we have made so many mistakes and acted against ethical principles, who are we to program an AI's ethics? We've acted out many times, doesn't that make us worth getting rid of to make the world more ethical?

We want something with intelligence and emotions, but that is incredibly difficult to make happen, some claim it's impossible. I'm not sure we're there yet, but we have the potential to be soon, and the AI right now is just a stepping stone to get there. The question is, should we even go there? I'm going to let you guys ponder on that yourselves.




## REFERENCES:

OPENAI. 2023. “CHATGPT.” CHAT.OPENAI.COM. OPENAI. 2023. HTTPS://CHAT.OPENAI.COM/CHAT.
---

{% if page.tags %}
<div class="tag-row">
  {% for tag in page.tags %}
    <a class="tag-chip" href="{{ '/topics/' | relative_url }}#{{ tag | slugify }}">#{{ tag }}</a>
  {% endfor %}
</div>
{% endif %}
